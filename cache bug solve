new step
Introduce a generic backend observability and caching framework for KPIs.

Rules:
- Do NOT change existing endpoint names
- Do NOT change function signatures
- Do NOT introduce pagination
- Do NOT modify response schemas
- Backend only (FastAPI + Oracle)

Tasks:
1. Implement a shared in-memory cache service with TTL
2. Implement a shared logging/timing utility
3. Create a reusable decorator or wrapper that:
   - wraps any read_* KPI endpoint
   - handles cache lookup and storage
   - measures execution time
4. Cache key must be deterministic using:
   - endpoint name
   - request path
   - query parameters
5. Standardize logs across all KPIs:
   - CACHE_HIT / CACHE_MISS
   - EMAIL_ROWS_FETCHED
   - TBOSS_ROWS_FETCHED
   - FINAL_RESPONSE_ROWS
   - EXEC_TIME_SECONDS
6. Apply this wrapper to all current KPI endpoints
7. Ensure new KPI endpoints only need the wrapper applied

Logging format (mandatory):
[CACHE] HIT | MISS
[DB] EMAIL_ROWS_FETCHED=<int>
[DB] TBOSS_ROWS_FETCHED=<int>
[RESPONSE] ROWS=<int>
[PERF] EXEC_TIME=<seconds>

Goal:
- Zero duplication when adding new KPIs
- Predictable performance across dashboards
- Logs alone should explain slowdowns or cache misses








end
A bug was introduced after adding in-memory caching.

Current symptoms:
- API throws runtime errors after cache was added
- Data sometimes does not load or crashes on navigation
- Error observed: UnboundLocalError / stale or missing cached values
- Issue started ONLY after caching prompt was applied

Rules (STRICT):
- Do NOT rename any function, variable, endpoint, or response model
- Do NOT change API behavior or output structure
- Do NOT remove caching entirely
- Do NOT add new dependencies or external services

Your task:
1. Identify exactly where caching logic is unsafe or incorrect
2. Fix cache initialization, cache read, and cache fallback paths
3. Ensure all cached values are:
   - Always initialized
   - Never referenced before assignment
   - Safely returned even on cache miss
4. Ensure cache invalidation does NOT break read endpoints
5. Ensure concurrent requests do NOT corrupt cache state

Specifically verify:
- No local variables depend on cached values without defaults
- Cache miss always falls back to original DB logic
- Cache hit never skips required variable initialization
- Exceptions do NOT leave cache in partial state

Constraints:
- Keep function names and variables exactly the same
- Minimal code changes only
- Logic outcome must remain identical to pre-cache version

Output:
- Fixed backend code only
- Brief explanation of what was wrong in caching logic